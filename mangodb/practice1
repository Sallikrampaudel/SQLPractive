
1.

{
  "kind": "youtube#searchListResponse",
  "etag": "\"m2yskBQFythfE4irbTIeOgYYfBU/PaiEDiVxOyCWelLPuuwa9LKz3Gk\"",
  "nextPageToken": "CAUQAA",
  "regionCode": "KE",
  "pageInfo": {
    "totalResults": 4249,
    "resultsPerPage": 5
  },
  "items": [
    {
      "kind": "youtube#searchResult",
      "etag": "\"m2yskBQFythfE4irbTIeOgYYfBU/QpOIr3QKlV5EUlzfFcVvDiJT0hw\"",
      "id": {
        "kind": "youtube#channel",
        "channelId": "UCJowOS1R0FnhipXVqEnYU1A"
      }
    },
    {
      "kind": "youtube#searchResult",
      "etag": "\"m2yskBQFythfE4irbTIeOgYYfBU/AWutzVOt_5p1iLVifyBdfoSTf9E\"",
      "id": {
        "kind": "youtube#video",
        "videoId": "Eqa2nAAhHN0"
      }
    },
    {
      "kind": "youtube#searchResult",
      "etag": "\"m2yskBQFythfE4irbTIeOgYYfBU/2dIR9BTfr7QphpBuY3hPU-h5u-4\"",
      "id": {
        "kind": "youtube#video",
        "videoId": "IirngItQuVs"
      }
    }
  ]
}


This is a sample data generated by youtube. 

Expectations:  To provide commands
1.	To insert this data into a mongo db collection with the name as youtube.
2.	Return the only regionCode for only those docs where channelId is UCJowOS1R0FnhipXVqEnYU1A 
3.	Write a pyspark code to read this document into spark dataframe.

sales.csv
ProductId, Sales
1,100
2,200
3,300
1,100
2,200
3,300
1,100
2,200
3,300



Create sales.csv in spark dafarame and write to mongodb in sales collection.


ANSWER:
To create collections:
db.createCollection("youtube")

To insert :
db.youtube.insertOne({
  "kind": "youtube#searchListResponse",
  "etag": "\"m2yskBQFythfE4irbTIeOgYYfBU/PaiEDiVxOyCWelLPuuwa9LKz3Gk\"",
  "nextPageToken": "CAUQAA",
  "regionCode": "KE",
  "pageInfo": {"totalResults": 4249, "resultsPerPage": 5},
  "items": [
    {
      "kind": "youtube#searchResult",
      "etag": "\"m2yskBQFythfE4irbTIeOgYYfBU/QpOIr3QKlV5EUlzfFcVvDiJT0hw\"",
      "id": {"kind": "youtube#channel", "channelId": "UCJowOS1R0FnhipXVqEnYU1A"}
    },
    {
      "kind": "youtube#searchResult",
      "etag": "\"m2yskBQFythfE4irbTIeOgYYfBU/AWutzVOt_5p1iLVifyBdfoSTf9E\"",
      "id": {"kind": "youtube#video", "videoId": "Eqa2nAAhHN0"}
    },
    {
      "kind": "youtube#searchResult",
      "etag": "\"m2yskBQFythfE4irbTIeOgYYfBU/2dIR9BTfr7QphpBuY3hPU-h5u-4\"",
      "id": {"kind": "youtube#video", "videoId": "IirngItQuVs"}
    }
  ]
});


-	To Return the only regionCode for only those docs where channelId is UCJowOS1R0FnhipXVqEnYU1A 

db.youtube.find(
  {"items.id.channelId": "UCJowOS1R0FnhipXVqEnYU1A"},
  {"regionCode": 1, "_id": 0}
);


-	To Write a pyspark code to read this document into spark dataframe.

df = spark.read.format("com.mongodb.spark.sql.DefaultSource").option("uri", "mongodb+srv:// username:password@clusterName /db2.youtube").load()


-	To Create sales.csv in spark dafarame and write to mongodb in sales collection.

from pyspark.sql import SparkSession from 
pyspark.sql.types import StructType, StructField, IntegerType


spark = SparkSession.builder.appName("CreateDataFrame").getOrCreate()

# Define the schema for the DataFrame 
schema = StructType([ StructField("ProductId", IntegerType(), True), StructField("Sales", IntegerType(), True) ])

# Define the data as a list of tuples 
data = [ (1, 100), (2, 200), (3, 300), (1, 100), (2, 200), (3, 300), (1, 100), (2, 200), (3, 300) ]

# Create the DataFrame 
sales_df = spark.createDataFrame(data, schema)

# To wite dataframe
sales_df.write.format("com.mongodb.spark.sql.DefaultSource").mode("append").option("uri", "mongodb+srv://username:password@clusterName /db2.sales").save()
